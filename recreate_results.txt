Results from running classification.py:

+++++++++++++++++ Review Features ++++++++++++++++
(2661, 12) (666, 12)
==========Logistic Regression==========
AUC, Accuracy, TN, TP, F1 Score
0.8381762973868238, 0.7852852852852853, 0.8447368421052631, 0.7062937062937062, 0.7837976660156704
==========Random Forest==========
AUC, Accuracy, TN, TP, F1 Score
0.8736105999263895, 0.8108108108108109, 0.8578947368421053, 0.7482517482517482, 0.809925904113537
==========RF Feature Importance==========
[('share_photo', 0.20189505584049752), ('max_days_between_reviews', 0.12463681594032641), ('n_of_reviews', 0.11947505628860812), ('share_5star', 0.09633424737167086), ('avg_days_between_reviews', 0.08939514432662966), ('stdev_days_between_reviews', 0.07944151009554849), ('tfidf_review_body', 0.07278347875123893), ('avg_review_rating', 0.05503515645978172), ('std_review_len', 0.05363491227721834), ('share_helpful_reviews', 0.05344478207096878), ('share_1star', 0.049552731857900545), ('min_days_between_reviews', 0.004371108719610656)]
==========SVC Linear==========
AUC, Accuracy, TN, TP, F1 Score
0.8386915715863084, 0.7867867867867868, 0.8578947368421053, 0.6923076923076923, 0.784614584713842
==========XGBoost==========
AUC, Accuracy, TN, TP, F1 Score
0.8718071402281928, 0.7867867867867868, 0.8131578947368421, 0.7517482517482518, 0.7867867867867868

+++++++++++++++++ Image Features ++++++++++++++++

(2661, 12) (666, 12)
==========Logistic Regression==========
AUC, Accuracy, TN, TP, F1 Score
0.6307738314317262, 0.6201201201201201, 0.8421052631578947, 0.32517482517482516, 0.590864600848607
==========Random Forest==========
AUC, Accuracy, TN, TP, F1 Score
0.5918062200956938, 0.6006006006006006, 0.7973684210526316, 0.33916083916083917, 0.5776275677352662
==========RF Feature Importance==========
[('min_sim_product', 0.10018625910676031), ('max_sim_product', 0.09056486671805858), ('std_sim_product', 0.08552419336874915), ('mean_sim', 0.08544355852259425), ('mean_sim_review', 0.08517123494777983), ('mean_sim_product', 0.08475367404506845), ('max_sim', 0.0799997545568708), ('max_sim_review', 0.07888925853966497), ('min_sim_review', 0.0781312041238371), ('std_sim_review', 0.07795753648094858), ('min_sim', 0.07751960171511069), ('std_sim', 0.07585885787455732)]
==========SVC Linear==========
AUC, Accuracy, TN, TP, F1 Score
0.6286667280088333, 0.5930930930930931, 0.9, 0.1853146853146853, 0.5294013999556516
==========XGBoost==========
AUC, Accuracy, TN, TP, F1 Score
0.5690973500184027, 0.5720720720720721, 0.7289473684210527, 0.36363636363636365, 0.5579325430012161

+++++++++++++++++ Network Features ++++++++++++++++

(2661, 4) (666, 4)
==========Logistic Regression==========
AUC, Accuracy, TN, TP, F1 Score
0.8707627898417372, 0.8018018018018018, 0.8868421052631579, 0.6888111888111889, 0.798791120513186
==========Random Forest==========
AUC, Accuracy, TN, TP, F1 Score
0.8893218623481782, 0.8243243243243243, 0.8447368421052631, 0.7972027972027972, 0.8243618906036388
==========RF Feature Importance==========
[('clustering_coef', 0.39137067281910726), ('eigenvector_cent', 0.3140221194893345), ('w_degree', 0.15166562177404172), ('pagerank', 0.14294158591751663)]
==========SVC Linear==========
AUC, Accuracy, TN, TP, F1 Score
0.8740476628634523, 0.7957957957957958, 0.9105263157894737, 0.6433566433566433, 0.7904053121444427
==========XGBoost==========
AUC, Accuracy, TN, TP, F1 Score
0.8833824070666176, 0.8108108108108109, 0.8368421052631579, 0.7762237762237763, 0.810727179728423

+++++++++++++++++ Top 2 Network Features ++++++++++++++++

(2661, 2) (666, 2)
==========Logistic Regression==========
AUC, Accuracy, TN, TP, F1 Score
0.8552125506072875, 0.7927927927927928, 0.8736842105263158, 0.6853146853146853, 0.790008321029824
==========Random Forest==========
AUC, Accuracy, TN, TP, F1 Score
0.8785379094589622, 0.8123123123123123, 0.8315789473684211, 0.7867132867132867, 0.8124300280982839
==========RF Feature Importance==========
[('clustering_coef', 0.5298404094803572), ('eigenvector_cent', 0.4701595905196428)]
==========SVC Linear==========
AUC, Accuracy, TN, TP, F1 Score
0.8537035333087966, 0.7987987987987988, 0.8552631578947368, 0.7237762237762237, 0.7974725433015319
==========XGBoost==========
AUC, Accuracy, TN, TP, F1 Score
0.8760627530364373, 0.7987987987987988, 0.8131578947368421, 0.7797202797202797, 0.7991161741345159

+++++++++++++++++ All Features ++++++++++++++++

(2661, 28) (666, 28)
==========Logistic Regression==========
AUC, Accuracy, TN, TP, F1 Score
0.9212642620537357, 0.8573573573573574, 0.9, 0.8006993006993007, 0.8566464404686078
==========Random Forest==========
AUC, Accuracy, TN, TP, F1 Score
0.9320206109679794, 0.8618618618618619, 0.8842105263157894, 0.8321678321678322, 0.8617370781296746
==========RF Feature Importance==========
[('clustering_coef', 0.1877525158268186), ('eigenvector_cent', 0.16538601433218117), ('share_photo', 0.07506970911486284), ('w_degree', 0.063263074229649), ('n_of_reviews', 0.05541864638122459), ('max_days_between_reviews', 0.048968902709185275), ('pagerank', 0.04557291958070268), ('share_5star', 0.04123013694926203), ('tfidf_review_body', 0.0293445270627716), ('avg_days_between_reviews', 0.026597631857420104), ('stdev_days_between_reviews', 0.024482258843597914), ('avg_review_rating', 0.023491125652205402), ('std_review_len', 0.01971855621269203), ('share_1star', 0.019514918653940547), ('share_helpful_reviews', 0.018755573798030528), ('max_sim', 0.017987687236664936), ('min_sim', 0.014363470602327769), ('max_sim_review', 0.013630406969165284), ('min_sim_review', 0.013555040361118638), ('mean_sim_product', 0.013401173438639415), ('std_sim', 0.013140512781523546), ('min_sim_product', 0.012701900969310644), ('std_sim_product', 0.01166611015163618), ('max_sim_product', 0.011065867355089427), ('std_sim_review', 0.010674547059386067), ('mean_sim', 0.010346346903711171), ('mean_sim_review', 0.009778225133903404), ('min_days_between_reviews', 0.0031221998329793886)]
==========SVC Linear==========
AUC, Accuracy, TN, TP, F1 Score
0.9204453441295546, 0.8543543543543544, 0.8921052631578947, 0.8041958041958042, 0.8538027110332664
==========XGBoost==========
AUC, Accuracy, TN, TP, F1 Score
0.937523003312477, 0.8693693693693694, 0.9, 0.8286713286713286, 0.8690205426300642

+++++++++++++++++ All Text ++++++++++++++++

(2661, 1000) (666, 1000)
==========Logistic Regression==========
AUC, Accuracy, TN, TP, F1 Score
0.7687983069562018, 0.7312312312312312, 0.7736842105263158, 0.6748251748251748, 0.7307927465719577
==========Random Forest==========
AUC, Accuracy, TN, TP, F1 Score
0.8551619433198381, 0.7717717717717718, 0.9315789473684211, 0.5594405594405595, 0.7608641357163234
==========RF Feature Importance==========
[('also', 0.01671858753316468), ('conveni', 0.016139737317937924), ('realli', 0.009202886943571879), ('realli good', 0.008870636889890393), ('qualiti good', 0.00866722241156883), ('satisfi', 0.008216968484611273), ('great product', 0.006532196033162575), ('alway', 0.006279200480730451), ('ship', 0.0060832920645588675), ('describ', 0.0056946597971620425), ('howev', 0.00548795743744288), ('like much', 0.005281127714399274), ('simpl', 0.005233219660436288), ('worri', 0.005212472953939269), ('compani', 0.0050226913505416705), ('work great', 0.00461037715377882), ('year', 0.0044298702320684676), ('disappoint', 0.004320167613175103), ('recommend', 0.0043105868635230325), ('easi', 0.004212737022555049), ('exactli', 0.004084445558635333), ('would', 0.004064872169070019), ('excel', 0.0040169776484540115), ('month', 0.003990603619481155), ('order', 0.003962267738226853), ('super', 0.0038540899777283815), ('happi', 0.003673917442936127), ('star', 0.0035845295266419964), ('surpris', 0.0035615979902482164), ('make', 0.0035414288238688457), ('review', 0.003404262049484221), ('pretti', 0.0032816270325283147), ('servic', 0.003180308427291049), ('christma', 0.003167874641599889), ('return', 0.0031139824459586675), ('amazon', 0.003089893872231639), ('friend', 0.0030626760199078135), ('advertis', 0.003032594813425382), ('probabl', 0.003025273254762361), ('beauti', 0.0029968253247598664), ('thank', 0.0029881030665947017), ('long time', 0.002978845555760522), ('video', 0.002912541507499029), ('unfortun', 0.002868846875737489), ('still', 0.0028644968370232916), ('though', 0.0028411533303441543), ('love', 0.002836321137669355), ('help', 0.0027757425003828782), ('long', 0.002758669215538249), ('purchas', 0.002742530936249731)]
==========SVC Linear==========
AUC, Accuracy, TN, TP, F1 Score
0.7485829959514171, 0.7072072072072072, 0.75, 0.6503496503496503, 0.7068730728861448
==========XGBoost==========
AUC, Accuracy, TN, TP, F1 Score
0.8585066249539934, 0.7867867867867868, 0.8789473684210526, 0.6643356643356644, 0.7831560807295164


Results from running clustering.py:

cluster_ID
1     8064
2     2797
3     8239
4     3222
5      594
6     1429
7     1534
8      912
9     2133
10    4826
11    5064
12    2800
13    3549
14     913
15     656
16    2264
17    3727
18    6487
19    1594
20    3781
Name: product_ID, dtype: int64
================ CLUSTER 1====================
Shape of train and test: (3408, 16) (8064, 16)
52 5 1
================ CLUSTER 2====================
Shape of train and test: (3408, 16) (2797, 16)
0 0 0
================ CLUSTER 3====================
Shape of train and test: (3408, 16) (8239, 16)
0 0 0
================ CLUSTER 4====================
Shape of train and test: (3408, 16) (3222, 16)
1 0 0
================ CLUSTER 5====================
Shape of train and test: (3408, 16) (594, 16)
350 158 36
================ CLUSTER 6====================
Shape of train and test: (3408, 16) (1429, 16)
28 4 0
================ CLUSTER 7====================
Shape of train and test: (3408, 16) (1534, 16)
335 147 39
================ CLUSTER 8====================
Shape of train and test: (3408, 16) (912, 16)
0 0 0
================ CLUSTER 9====================
Shape of train and test: (3408, 16) (2133, 16)
10 1 0
================ CLUSTER 10====================
Shape of train and test: (3408, 16) (4826, 16)
0 0 0
================ CLUSTER 11====================
Shape of train and test: (3408, 16) (5064, 16)
9 2 1
================ CLUSTER 12====================
Shape of train and test: (3408, 16) (2800, 16)
0 0 0
================ CLUSTER 13====================
Shape of train and test: (3408, 16) (3549, 16)
140 15 4
================ CLUSTER 14====================
Shape of train and test: (3408, 16) (913, 16)
11 0 0
================ CLUSTER 15====================
Shape of train and test: (3408, 16) (656, 16)
0 0 0
================ CLUSTER 16====================
Shape of train and test: (3408, 16) (2264, 16)
2 0 0
================ CLUSTER 17====================
Shape of train and test: (3408, 16) (3727, 16)
63 16 4
================ CLUSTER 18====================
Shape of train and test: (3408, 16) (6487, 16)
6 0 0
================ CLUSTER 19====================
Shape of train and test: (3408, 16) (1594, 16)
0 0 0
================ CLUSTER 20====================
Shape of train and test: (3408, 16) (3781, 16)
6 0 0
